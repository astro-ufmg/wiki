{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"2025/12/15/introdu%C3%A7%C3%A3o-a-mpi-e-petsc-em-python/","title":"Introdu\u00e7\u00e3o a MPI e PETSC em Python","text":"<p>Esta \u00e9 uma breve introdu\u00e7\u00e3o a utiliza\u00e7\u00e3o do MPI e o PETSC em programas escritos em Python. O material \u00e9 escrito em forma de exemplos de complexidade incremental. Cada caso procura explorar da forma mais simples possivel como alguns aspectos fundamentais destas duas bibliotecas est\u00e3o embutidos no c\u00f3digo. Assume-se que o leitor tenha instalado os pacotes mpi4py e petsc4py. </p> <p>Nota</p> <p>O <code>mpi4py</code> requer a instala\u00e7\u00e3o de alguma distribui\u00e7\u00e3o do MPI (OpenMPI, MPICH, ...). Se a instala\u00e7\u00e3o do <code>petsc4py</code> esta utilizando a vers\u00e3o do PETSc j\u00e1 presente no sistema, \u00e9 preciso certificar que tal vers\u00e3o foi linkada a mesma vers\u00e3o do MPI que esta sendo utilizada pelo mpi4py. Caso contr\u00e1rio, erros estranhos referentes a m\u00e1 decodifica\u00e7\u00e3o de mensagens do MPI podem ocorrer.</p>"},{"location":"2025/12/15/introdu%C3%A7%C3%A3o-a-mpi-e-petsc-em-python/#um-hello-world","title":"Um hello world","text":"<p>Em sua forma mais simples, o MPI consiste em rodar v\u00e1rias r\u00e9plicas do mesmo programa e executar chamadas em sua biblioteca quando quisermos que estes processos comuniquem. Neste caso simples (mas assustadoramente comum) cada instancia se diferencia por seu rank, um n\u00famero inteiro maior ou igual a zero.</p> <p>00-mpi-hello-world.py<pre><code>from mpi4py import MPI\n\nrank = MPI.COMM_WORLD.Get_rank()\nsize = MPI.COMM_WORLD.Get_size()\n\nprint(f\"Hello from {rank} out of {size}\")\n</code></pre> Rodando o programa com 2 mpi slots, resulta: <pre><code>$ mpirun -n 2 python 00-mpi-hello-world.py\nHello from 1 out of 2\nHello from 0 out of 2\n</code></pre></p> <p>Neste caso nenhuma comunica\u00e7\u00e3o foi feita entre os programas. Eles s\u00f3 iniciaram, escreveram na tela e sairam.</p> <p>Nota</p> <p>No MPI, \u00e9 possivel ter grupos de processos que tomam acoes coletivas separadamente, como se cada grupo fosse uma sala de chat. O mais comum \u00e9 ter um \u00fanico grupo de processos que rodam r\u00e9plicas de um mesmo programa, com caminhos de execuc\u00e3o bem parecios e realizam operac\u00f5es entre si. O grupo ou comunicador primario \u00e9 referenciado por <code>COMM_WORLD</code>. </p>"},{"location":"2025/12/15/introdu%C3%A7%C3%A3o-a-mpi-e-petsc-em-python/#caminhos-de-execucao-diferentes","title":"Caminhos de execu\u00e7\u00e3o diferentes","text":"<p>As vezes, queremos que processos diferentes realizem tarefas diferentes, como por exemplo, escrever um arquivo ou gerar um grafico serialmente. Tendo o rank atual em m\u00e3os, isto \u00e9 f\u00e1cil como escrever uma condicional:</p> 01-mpi-branches.py<pre><code>from mpi4py import MPI\nfrom time import sleep\n\nrank = MPI.COMM_WORLD.Get_rank()\n\ndef work():\n    sleep(1.0)\n    print(f\"Done working {rank}\")\n\ndef work_more():\n    sleep(2.0)\n    print(f\"Done working {rank}\")\n\nif rank != 0:\n    work()\nelse:\n    work_more()\n</code></pre> <pre><code>$ mpirun -n 2 python 01-mpi-branches.py\nDone working 1\nDone working 0\n</code></pre> <p>Dependendo do rank da instancia que estamos, o programa pode tomar caminhos de execuc\u00e3o distintos. Para evitar condicoes de corrida na escrita ou exportacao de dados, \u00e9 comum sincronizar os dados para uma unica instancia e realizar as operacoes somente dela.</p>"},{"location":"2025/12/15/introdu%C3%A7%C3%A3o-a-mpi-e-petsc-em-python/#basico-de-sincronizacao","title":"B\u00e1sico de sincroniza\u00e7\u00e3o","text":"<p>A princ\u00edpio, cada inst\u00e2ncia do MPI roda em paralelo (n\u00e3o \u00e9 necessariamente assim) o que \u00e9 um problema quando precisamos nos certificar que alguma parte do c\u00f3digo seja executada por um \u00fanico rank por vez. Neste caso, podemos utilizar uma primitiva de sincroniza\u00e7\u00e3o chamada Mutex:</p> 02-mpi-mutex.py<pre><code>from mpi4py import MPI\nfrom mpi4py.util import sync\nfrom time import sleep\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\n\ndef print_list():\n    for i in range(5):\n        print(f\"[rank {rank}] item {i}\")\n        sleep(0.1)\n    print(f\"[rank {rank}] done\")\n\nmutex = sync.Mutex(comm=comm)\n\nprint_list()\n\nwith mutex:\n    print_list()\n</code></pre> <pre><code>$ mpirun -n 2 python 02-mpi-mutex.py\n[rank 1] item 0\n[rank 0] item 0\n[rank 0] item 1\n[rank 1] item 1\n[rank 0] item 2\n[rank 1] item 2\n[rank 1] item 3\n[rank 0] item 3\n[rank 0] item 4\n[rank 1] item 4\n[rank 1] done\n[rank 0] done\n[rank 1] item 0\n[rank 1] item 1\n[rank 1] item 2\n[rank 1] item 3\n[rank 1] item 4\n[rank 1] done\n[rank 0] item 0\n[rank 0] item 1\n[rank 0] item 2\n[rank 0] item 3\n[rank 0] item 4\n[rank 0] done\n</code></pre> <p>Mutex (que significa Mutual exclusive e as vezes \u00e9 chamado de lock) \u00e9 uma forma de garantir que s\u00f3 uma instancia tenha acesso a algum recurso por vez. Note que na primeira chamada do <code>print_list()</code> as saidas intercalam entre os dois processos. Quando a funcao \u00e9 chamada ao adiquirir o mutex, um processo espera o outro terminar.</p> <p>Esta \u00e9 a forma mais facil de evitar condicoes de corrida.</p> <p>Nota</p> <p>Usu\u00e1rios do MPI em linguagens de mais baixo n\u00edvel, que interagem diretamente com a biblioteca do MPI v\u00e3o perceber que n\u00e3o existe um objeto tal como o Mutex. A interface do <code>mpi4py</code> prov\u00e9m esta e algumas outras primitivas de sincroniza\u00e7\u00e3o constru\u00eddas em cima das primitivas de troca de mensagem do MPI.</p>"},{"location":"2025/12/15/introdu%C3%A7%C3%A3o-a-mpi-e-petsc-em-python/#particionando-vetores-espacialment-no-petsc","title":"Particionando vetores espacialment no PETSc","text":"<p>Movendo agora para um exemplo com o petsc4py, vejamos como particionar espacialmente uma grade em diferentes processos do MPI.  </p> 03-petsc-global-local.py<pre><code>from mpi4py.util import sync\nfrom petsc4py import PETSc\n\ncomm = PETSc.COMM_WORLD\nrank = comm.getRank()\n\nn = 10\ndm = PETSc.DMDA().create([n], dof=1, stencil_width=1, comm=comm)\n\nglobal_vec = dm.createGlobalVector() \nlocal_vec = dm.createLocalVector()\n\nglobal_vec.set(rank)\nglobal_vec.assemble()\n\ndm.globalToLocal(global_vec, local_vec)\n\nmutex = sync.Mutex(comm = comm.tompi4py())\n\nwith mutex:\n    print(f\"rank {rank}:\")\n    print(\"  global:\", global_vec.getArray())\n    print(\"  local :\", local_vec.getArray())\n ```\n\n`DMDA` \u00e9 o nome dado a um objeto do PETSc que permite codificar informa\u00e7\u00f5es de conectividade de uma grade estruturada (quadrilateral). Utilizamos este objeto posteriormente pra criar vetores e realizar comunica\u00e7\u00f5es coletivas facilitando a parti\u00e7\u00e3o de um domn\u00ednio f\u00edsico entre diferentes processos. \n\n ```\n$ mpirun -n 2 python 03-petsc-global-local.py\nrank 1:\n  global: [1. 1. 1. 1. 1.]\n  local : [0. 1. 1. 1. 1. 1.]\nrank 0:\n  global: [0. 0. 0. 0. 0.]\n  local : [0. 0. 0. 0. 0. 1.]\n</code></pre> <p>Na nomeclatura do PETSc, global \u00e9 uma fatia (local) do vetor em questao, enquanto local \u00e9 esta fatia com os ghost points. Note que: 1. Com <code>n = 10</code> em <code>-n 2</code> o <code>global_vec</code> tem 5 pontos enquanto o <code>local_vec</code> tem 6. Experimente mudar o valor de <code>stencil_width</code>. 2. <code>global_vec.set(rank)</code> enche o vetor com o valor do rank atual  3. Ao chamar <code>dm.globalToLocal(global_vec, local_vec)</code> sincronizamos o valor dos ghost points entre os processos.</p> <p>Nota</p> <p>As interfaces <code>DM*</code> n\u00e3o s\u00e3o as mais primitivas no PETSc. Um vetor criado sem a utiliza\u00e7\u00e3o de algum variante deste objeto <code>DM</code> ser\u00e1 trivialmente particionado entre os processos. Isto ocorre quando, por exemplo, queremos apenas resolver um problema de \u00e1lgebra linear sem embutir qualquer informa\u00e7\u00e3o sobre a conectividade dos nossos operadores.</p>"},{"location":"2025/12/15/introdu%C3%A7%C3%A3o-a-mpi-e-petsc-em-python/#exportando-os-vetores-para-uma-unica-instancia","title":"Exportando os vetores para uma \u00fanica inst\u00e2ncia","text":"<p>Corriqueiramente, queremos utilizar o vetor (ou campo) completo em uma tarefa que n\u00e3o pode ser realizada em paralelo. Exemplos disto s\u00e3o polotagem dos resultados e exporta\u00e7\u00e3o para um arquivo (\u00e9 poss\u00edvel mas n\u00e3o trivial realizar escritas em paralelo). Neste caso, \u00e9 comum reconstruir o vetor completo em um \u00fanico processo, comumente o com rank zero (ele costumar se o mais lento). </p> 04-gather-on-zero.py<pre><code>from mpi4py.util import sync\nfrom petsc4py import PETSc\n\ncomm = PETSc.COMM_WORLD\nrank = comm.getRank()\n\nn = 10\ndm = PETSc.DMDA().create([n], dof=1, stencil_width=1, comm=comm)\n\nglobal_vec = dm.createGlobalVector()\nlocal_vec = dm.createLocalVector()\n\nglobal_vec.set(rank)\nglobal_vec.assemble()\n\ndm.globalToLocal(global_vec, local_vec)\n\nif rank == 0:\n    vec_zero = PETSc.Vec().createSeq(global_vec.getSize(), comm=PETSc.COMM_SELF)\nelse:\n    vec_zero = PETSc.Vec().createSeq(0, comm=PETSc.COMM_SELF)\n\nscatter, _ = PETSc.Scatter().toZero(global_vec)\nscatter.scatter(\n    global_vec, vec_zero, PETSc.InsertMode.INSERT, PETSc.ScatterMode.FORWARD\n)\n\nprint(f\"[rank {rank}]: \", vec_zero.getArray())\n</code></pre> <p>Note que o <code>vec_zero</code> tem tipos diferentes em ranks diferentes. Isto evita critar uma copia do vetor global em cada rank. Sobre a comunica\u00e7\u00e3o, a fun\u00e7\u00e3o <code>PETSc.Scatter().toZero(...)</code> retorna uma tupla com dois contextos de scatter: global para local e local para local. Utilizamos o global para local.</p> <pre><code>$ mpirun -n 2 python 04-gather-on-zero.py\n[rank 1]:  []\n[rank 0]:  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n</code></pre> <p>Note que o vetor <code>vec_zero</code> n\u00e3o ocupa mem\u00f3ria no rank 1. Se quisessemos ser super eficientes sobre memoria, poder\u00edamos receber, no rank zero, cada peda\u00e7o de um vetor sequencialmente, e realizar a opera\u00e7\u00e3o desejada. Isto evitaria a situa\u00e7\u00e3o em que o programa por completo teria dois campos inteiros alocatos em um \u00fanico instante: \\(N\\) peda\u00e7os distribu\u00eddos em \\(N\\) ranks e um inteiro do rank zero.</p> <p>Um coment\u00e1rio final sobre a diferen\u00e7a de nomeclatura entre as duas bibliotecas. No PETSc scatter s\u00e3o opera\u00e7\u00f5es genericas que redistribuem dados entre os processos. Na nomeclatura tradicional, por\u00e9m, scatter se refere ao caso em que enviamos uma informa\u00e7\u00e3o da instancia local para as outras e gather \u00e9 quando recebemos. As especifica\u00e7\u00e3o do MPI tamb\u00e9m disponibiliza algumas opera\u00e7\u00f5es que combinam as duas, chamadas de reduce. Um reduce pode somar todos os vetores distribuidos elemento a elemento ou tirar o m\u00e1ximo, por exemplo.</p>"},{"location":"2025/12/15/postando-no-blog-da-astro/","title":"Postando no blog da astro","text":"<p>Todos queremos compartilhar o que sabemos, mas raramente temos a oportunidade de estarmos no mesmo ambiente, no mesmo instante e ou com a mesma disponibilidade. A solu\u00e7\u00e3o para isto \u00e9 o blog da astro!. </p> <p>O blog \u00e9 feito</p>"},{"location":"archive/2025/","title":"2025","text":""},{"location":"category/python/","title":"python","text":""},{"location":"category/mpi/","title":"mpi","text":""},{"location":"category/meta/","title":"meta","text":""}]}